{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini ve LangChain ile LLM API'larÄ±nÄ± Ã‡aÄŸÄ±rma GiriÅŸ ğŸ¦œğŸ”—\n",
    "\n",
    "Bu notebook'ta LangChain aracÄ±lÄ±ÄŸÄ±yla LLM API'larÄ±nÄ± nasÄ±l kullanacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸreneceksiniz. Ã–rnek olarak Google'Ä±n Gemini API'sÄ±nÄ± kullanacaÄŸÄ±z. Bu notebook'un sonunda, LangChain kullanarak API Ã§aÄŸrÄ±larÄ± yapmayÄ± ve bunu neden yaptÄ±ÄŸÄ±mÄ±zÄ± bileceksiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Kurulum\n",
    "\n",
    "ğŸ‘‰ Kurulum aÅŸamasÄ±nda oluÅŸturduÄŸumuz `.env` dosyasÄ±ndaki ortam deÄŸiÅŸkenlerini yÃ¼klemek iÃ§in aÅŸaÄŸÄ±daki hÃ¼creyi Ã§alÄ±ÅŸtÄ±rÄ±n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ HÃ¼crenin Ã§Ä±ktÄ±sÄ± \"`True`\" mu? Harika! ArtÄ±k Gemini API ile kimlik doÄŸrulamasÄ± yapmak iÃ§in kullanÄ±lacak bir `GOOGLE_API_KEY` ortam deÄŸiÅŸkeni kurmuÅŸ olduk.\n",
    "\n",
    "EÄŸer deÄŸilse, yardÄ±m isteyin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basit Bir API Ã‡aÄŸrÄ±sÄ± Yapma\n",
    "\n",
    "Bu notebook'ta ÅŸunlarÄ±n nasÄ±l yapÄ±lacaÄŸÄ±nÄ± gÃ¶stereceÄŸiz:\n",
    "1. Google'Ä±n kendi kÃ¼tÃ¼phanesini kullanarak API Ã§aÄŸrÄ±sÄ± yapma.\n",
    "2. AynÄ± iÅŸlemi LangChain kullanarak yapma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Generative AI KÃ¼tÃ¼phanesini Kullanma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    contents=\"What is the capital of France?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`response` nesnesine bir gÃ¶z atalÄ±m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.candidates[0].content.parts[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GerÃ§ek cevabÄ± nasÄ±l alabileceÄŸinizi gÃ¶rÃ¼yor musunuz?\n",
    "\n",
    "Neyse ki, cevabÄ± hemen almak iÃ§in sadece `.text` Ã¶zelliÄŸini kullanabiliriz. Deneyin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini cevaplarÄ±nÄ± Markdown formatÄ±nda dÃ¶ndÃ¼rÃ¼r. Bunu kullanalÄ±m!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OluÅŸturma parametrelerini de deÄŸiÅŸtirebilirsiniz. `google.genai` kullanarak bunu ÅŸu ÅŸekilde yaparsÄ±nÄ±z:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types # We need to import types for the config\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    contents=\"Write a social media post about how much you're learning about transformers.\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=200,\n",
    "        temperature=1.0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harika. Ancak baÅŸka bir API denemek istediÄŸinizi dÃ¼ÅŸÃ¼nÃ¼n, Ã¶rneÄŸin OpenAI'nin veya Anthropic'in?\n",
    "\n",
    "OnlarÄ±n dokÃ¼mantasyonlarÄ±nÄ± incelemek ve tÃ¼m kodunuzu onlarÄ±n API'sini kullanacak ÅŸekilde yeniden yazmak zorunda kalÄ±rsÄ±nÄ±z. Tabii ki benzer olacaktÄ±r, ancak aynÄ± olmayacaktÄ±r.\n",
    "\n",
    "Neyse ki LangChain var!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Kullanma ğŸ¦œğŸ”—"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neden LangChain kullanÄ±rsÄ±nÄ±z?\n",
    "\n",
    "1. **Model-BaÄŸÄ±msÄ±z Kod**\n",
    "\n",
    "   LangChain, farklÄ± LLM saÄŸlayÄ±cÄ±larÄ± (Google, OpenAI, Anthropic, vb.) arasÄ±nda minimal kod deÄŸiÅŸikliÄŸi ile geÃ§iÅŸ yapmanÄ±zÄ± saÄŸlayan soyutlamalar sunar. Google API'sine doÄŸrudan kod yazarsanÄ±z, saÄŸlayÄ±cÄ± deÄŸiÅŸtirmek Ã¶nemli Ã¶lÃ§Ã¼de yeniden dÃ¼zenleme gerektirir.\n",
    "\n",
    "2. **BirleÅŸik ArayÃ¼z**\n",
    "\n",
    "   LangChain, altta yatan API'den baÄŸÄ±msÄ±z olarak farklÄ± LLM saÄŸlayÄ±cÄ±larÄ± arasÄ±nda etkileÅŸimleri standartlaÅŸtÄ±rÄ±r ve tutarlÄ± yÃ¶ntemler ile yanÄ±t formatlarÄ± sunar.\n",
    "\n",
    "3. **BileÅŸenlerle Ã‡alÄ±ÅŸabilirlik**\n",
    "\n",
    "   LangChain'in zincir ve pipeline mimarisi, tÃ¼m alt yapÄ±yÄ± kendiniz halletmeden prompt, bellek ve eriÅŸim sistemlerini birleÅŸtiren karmaÅŸÄ±k iÅŸ akÄ±ÅŸlarÄ± oluÅŸturmayÄ± kolaylaÅŸtÄ±rÄ±r.\n",
    "\n",
    "4. **YerleÅŸik AraÃ§lar**\n",
    "\n",
    "   LangChain, Ã§Ä±ktÄ± ayrÄ±ÅŸtÄ±rma, prompt ÅŸablonlarÄ± ve kendiniz uygulamanÄ±z gereken diÄŸer yardÄ±mcÄ± araÃ§larÄ± iÃ§erir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[LangChain'in chat entegrasyonlarÄ± listesi](https://docs.langchain.com/oss/python/integrations/chat)'ne gidin ve entegrasyon listesine bakÄ±n. Favori LLM saÄŸlayÄ±cÄ±nÄ±zÄ± bulabiliyor musunuz?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kodumuzda `chat_models.ChatGoogleGenerativeAI` kullanmak istemiyoruz Ã§Ã¼nkÃ¼ bu Ã¶zellikle Gemini iÃ§in yapÄ±lmÄ±ÅŸ. LLM'yi deÄŸiÅŸtirmek istersek, modeli baÅŸlatma ÅŸeklimizi deÄŸiÅŸtirmek zorunda kalÄ±rÄ±z. Neyse ki LangChain bir modeli baÅŸlatmak iÃ§in daha genel bir yol sunar.\n",
    "\n",
    "Gemini'yi tekrar kullanalÄ±m, ancak ÅŸimdi LangChain'in genel Chat Models'ini kullanarak.\n",
    "\n",
    "ğŸ‘‰ [LangChain'in \"Models\" dokÃ¼mantasyonu](https://docs.langchain.com/oss/python/langchain/models) sayfasÄ±na gidin ve Gemini kullanarak bir chat modelinin nasÄ±l baÅŸlatÄ±lacaÄŸÄ±nÄ± bulun.\n",
    "\n",
    "Ä°puÃ§larÄ±:\n",
    "1. Hemen \"Basic Usage\" bÃ¶lÃ¼mÃ¼ne gidin.\n",
    "2. Kullanmak istediÄŸiniz modeli seÃ§erek doÄŸru dokÃ¼mantasyonu hemen gÃ¶rebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin en temel kullanÄ±mÄ± sadece `.invoke()` metodunu kullanmaktÄ±r:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YanÄ±ta bir gÃ¶z atalÄ±m. Nesnenin tÃ¼m Ã¶znitelik ve metodlarÄ±nÄ± iÃ§eren `__dict__`'ini gÃ¼zel ÅŸekilde yazdÄ±rmak iÃ§in `pprint()` kullanÄ±yoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(response.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CevabÄ± Ã§Ä±karÄ±n ve gÃ¶rÃ¼ntÃ¼leyin. Markdown formatÄ±nda olduÄŸunu unutmayÄ±n, bu yÃ¼zden gÃ¼zel gÃ¶rÃ¼nmesini saÄŸlayabilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin temperature deÄŸerini `.temperature` Ã¶zniteliÄŸine eriÅŸerek kontrol edebilirsiniz. Deneyin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeli kullanmadan Ã¶nce, Ã¶zniteliklere yeni deÄŸerler atayarak oluÅŸturma parametrelerini de ayarlayabiliriz.\n",
    "\n",
    "Daha Ã¶nce Google'Ä±n kÃ¼tÃ¼phanesini kullanarak sosyal medya gÃ¶nderisi yazmak iÃ§in yaptÄ±ÄŸÄ±mÄ±zÄ±n eÅŸdeÄŸerini kodlamaya Ã§alÄ±ÅŸÄ±n.\n",
    "\n",
    "> _Not_: Normal olarak modelin `max_output_tokens` deÄŸerini ayarlayabilmemiz gerekir (modeli baÅŸlatÄ±rken veya daha sonra Ã¶zniteliÄŸi deÄŸiÅŸtirerek). _langchain_google_genai_'nin mevcut sÃ¼rÃ¼mÃ¼ (4.1.1) bir [hataya](https://github.com/langchain-ai/langchain-google/issues/1454) sahip ve bu Ã§alÄ±ÅŸmÄ±yor. GeÃ§ici Ã§Ã¶zÃ¼m? `max_output_tokens`'Ä± `.invoke()` metodunun bir parametresi olarak ayarlayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "steps"
    ]
   },
   "outputs": [],
   "source": [
    "# Set the maximum number of output tokens to 200\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Set the temperature to 1.0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Generate a response with the new settings\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Display the response\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bunun avantajÄ±? Bu LangChain Chat Model birÃ§ok baÅŸka API'yi destekleyebilir.\n",
    "\n",
    "BaÅŸka bir modele geÃ§mek iÃ§in deÄŸiÅŸtirmeniz gereken tek ÅŸeyler:\n",
    "1. DiÄŸer model iÃ§in bir API anahtarÄ± alÄ±n ve kodunuzda tanÄ±mlayÄ±n.\n",
    "2. Modeli baÅŸlatÄ±rken model ve saÄŸlayÄ±cÄ±yÄ± deÄŸiÅŸtirin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ã‡oklu Mesajlar\n",
    "\n",
    "`.invoke()` fonksiyonunu sadece tek bir mesajla kullanmak biraz kÄ±sÄ±tlayÄ±cÄ±.\n",
    "\n",
    "Åu gibi birden fazla mesaj saÄŸlayabilirsiniz:\n",
    "- `SystemMessage` veya sistem mesajlarÄ±: modelin nasÄ±l davranacaÄŸÄ±nÄ± sÃ¶ylemek iÃ§in\n",
    "- `HumanMessage` veya KullanÄ±cÄ± mesajlarÄ±: kullanÄ±cÄ±dan gelen girdi\n",
    "- `AIMessage` veya Asistan mesajlarÄ±: modelden gelen yanÄ±t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir sosyal medya yazarÄ± yapalÄ±m.\n",
    "\n",
    "Modele nasÄ±l davranacaÄŸÄ±nÄ± aÃ§Ä±klayan bir sistem mesajÄ± gÃ¶ndereceÄŸiz. Sonra kullanÄ±cÄ± mesajÄ±nda, kendimizi sadece yazacaÄŸÄ± konuyu vermekle sÄ±nÄ±rlayabiliriz.\n",
    "\n",
    "Bunu nasÄ±l yapacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸrenmek iÃ§in [LangChain'in \"Messages\" dokÃ¼mantasyonu](https://docs.langchain.com/oss/python/langchain/messages)'na bakÄ±n.\n",
    "\n",
    "Sistem mesajÄ± iÃ§in ilhama mÄ± ihtiyacÄ±nÄ±z var? Ä°ÅŸte baÅŸlamanÄ±z iÃ§in temel bir talimat:\n",
    "\n",
    "```python\n",
    "\"\"\"Sen Ãœretken AI Ã¶ÄŸrencisi iÃ§in gÃ¶nderiler yazan yaratÄ±cÄ± bir sosyal medya yazarÄ±sÄ±n.\n",
    "GÃ¶nderilerinde her zaman kelime oyunu ve harekete geÃ§irici Ã§aÄŸrÄ± bulunur.\n",
    "GÃ¶nderilerin maksimum 200 karakter uzunluÄŸundadÄ±r.\n",
    "Her zaman emoji kullanÄ±rsÄ±n.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "steps"
    ]
   },
   "outputs": [],
   "source": [
    "# Import the necessary classes\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Create a list of messages\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Generate a response using the list of messages\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Display the response\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ Tebrikler! ArtÄ±k LangChain kullanarak Ã§oklu mesajlarla temel prompt yazma konusunda uzmanlaÅŸtÄ±nÄ±z."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
