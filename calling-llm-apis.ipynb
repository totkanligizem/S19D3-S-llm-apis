{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a4e3141",
   "metadata": {},
   "source": [
    "# Gemini ve LangChain ile LLM API'larÄ±nÄ± Ã‡aÄŸÄ±rma GiriÅŸ ğŸ¦œğŸ”—\n",
    "\n",
    "Bu notebook'ta LangChain aracÄ±lÄ±ÄŸÄ±yla LLM API'larÄ±nÄ± nasÄ±l kullanacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸreneceksiniz. Ã–rnek olarak Google'Ä±n Gemini API'sÄ±nÄ± kullanacaÄŸÄ±z. Bu notebook'un sonunda, LangChain kullanarak API Ã§aÄŸrÄ±larÄ± yapmayÄ± ve bunu neden yaptÄ±ÄŸÄ±mÄ±zÄ± bileceksiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6c9aa5",
   "metadata": {},
   "source": [
    "## âš™ï¸ Kurulum\n",
    "\n",
    "ğŸ‘‰ Kurulum aÅŸamasÄ±nda oluÅŸturduÄŸumuz `.env` dosyasÄ±ndaki ortam deÄŸiÅŸkenlerini yÃ¼klemek iÃ§in aÅŸaÄŸÄ±daki hÃ¼creyi Ã§alÄ±ÅŸtÄ±rÄ±n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb9ca4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T14:03:52.325491Z",
     "iopub.status.busy": "2026-02-02T14:03:52.324840Z",
     "iopub.status.idle": "2026-02-02T14:03:52.340660Z",
     "shell.execute_reply": "2026-02-02T14:03:52.340158Z",
     "shell.execute_reply.started": "2026-02-02T14:03:52.325439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c77b13",
   "metadata": {},
   "source": [
    "ğŸ‘‰ HÃ¼crenin Ã§Ä±ktÄ±sÄ± \"`True`\" mu? Harika! ArtÄ±k Gemini API ile kimlik doÄŸrulamasÄ± yapmak iÃ§in kullanÄ±lacak bir `GOOGLE_API_KEY` ortam deÄŸiÅŸkeni kurmuÅŸ olduk.\n",
    "\n",
    "EÄŸer deÄŸilse, yardÄ±m isteyin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe164b3",
   "metadata": {},
   "source": [
    "## Basit Bir API Ã‡aÄŸrÄ±sÄ± Yapma\n",
    "\n",
    "Bu notebook'ta ÅŸunlarÄ±n nasÄ±l yapÄ±lacaÄŸÄ±nÄ± gÃ¶stereceÄŸiz:\n",
    "1. Google'Ä±n kendi kÃ¼tÃ¼phanesini kullanarak API Ã§aÄŸrÄ±sÄ± yapma.\n",
    "2. AynÄ± iÅŸlemi LangChain kullanarak yapma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5a41c6",
   "metadata": {},
   "source": [
    "## Google Generative AI KÃ¼tÃ¼phanesini Kullanma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f20e2f11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T14:03:57.538170Z",
     "iopub.status.busy": "2026-02-02T14:03:57.537734Z",
     "iopub.status.idle": "2026-02-02T14:03:57.901735Z",
     "shell.execute_reply": "2026-02-02T14:03:57.901415Z",
     "shell.execute_reply.started": "2026-02-02T14:03:57.538137Z"
    }
   },
   "outputs": [],
   "source": [
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca9169a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T14:03:59.758084Z",
     "iopub.status.busy": "2026-02-02T14:03:59.757351Z",
     "iopub.status.idle": "2026-02-02T14:04:00.949030Z",
     "shell.execute_reply": "2026-02-02T14:04:00.947540Z",
     "shell.execute_reply.started": "2026-02-02T14:03:59.758045Z"
    }
   },
   "outputs": [],
   "source": [
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    contents=\"What is the capital of France?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707cdfa0",
   "metadata": {},
   "source": [
    "`response` nesnesine bir gÃ¶z atalÄ±m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46c1d780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T14:04:03.115236Z",
     "iopub.status.busy": "2026-02-02T14:04:03.114547Z",
     "iopub.status.idle": "2026-02-02T14:04:03.122362Z",
     "shell.execute_reply": "2026-02-02T14:04:03.121420Z",
     "shell.execute_reply.started": "2026-02-02T14:04:03.115177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is **Paris**.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates[0].content.parts[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a1efd6",
   "metadata": {},
   "source": [
    "GerÃ§ek cevabÄ± nasÄ±l alabileceÄŸinizi gÃ¶rÃ¼yor musunuz?\n",
    "\n",
    "Neyse ki, cevabÄ± hemen almak iÃ§in sadece `.text` Ã¶zelliÄŸini kullanabiliriz. Deneyin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8106e8d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T14:04:05.626677Z",
     "iopub.status.busy": "2026-02-02T14:04:05.626049Z",
     "iopub.status.idle": "2026-02-02T14:04:05.633190Z",
     "shell.execute_reply": "2026-02-02T14:04:05.632394Z",
     "shell.execute_reply.started": "2026-02-02T14:04:05.626622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is **Paris**.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd9e94e",
   "metadata": {},
   "source": [
    "Gemini cevaplarÄ±nÄ± Markdown formatÄ±nda dÃ¶ndÃ¼rÃ¼r. Bunu kullanalÄ±m!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "972de244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T14:04:09.075390Z",
     "iopub.status.busy": "2026-02-02T14:04:09.074935Z",
     "iopub.status.idle": "2026-02-02T14:04:09.082673Z",
     "shell.execute_reply": "2026-02-02T14:04:09.081670Z",
     "shell.execute_reply.started": "2026-02-02T14:04:09.075354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The capital of France is **Paris**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4083211d",
   "metadata": {},
   "source": [
    "OluÅŸturma parametrelerini de deÄŸiÅŸtirebilirsiniz. `google.genai` kullanarak bunu ÅŸu ÅŸekilde yaparsÄ±nÄ±z:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55491b7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T14:11:03.436890Z",
     "iopub.status.busy": "2026-02-02T14:11:03.436329Z",
     "iopub.status.idle": "2026-02-02T14:11:05.744379Z",
     "shell.execute_reply": "2026-02-02T14:11:05.742754Z",
     "shell.execute_reply.started": "2026-02-02T14:11:03.436843Z"
    }
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types # We need to import types for the config\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    contents=\"Write a social media post about how much you're learning about transformers.\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=200,\n",
    "        temperature=1.0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08737bbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T14:11:08.318855Z",
     "iopub.status.busy": "2026-02-02T14:11:08.318289Z",
     "iopub.status.idle": "2026-02-02T14:11:08.325389Z",
     "shell.execute_reply": "2026-02-02T14:11:08.324635Z",
     "shell.execute_reply.started": "2026-02-02T14:11:08.318798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are a few options for a social media post about learning about transformers, choose the one that best fits your style and platform!\n",
       "\n",
       "**Option 1: Enthusiastic & Slightly Technical**\n",
       "\n",
       "ğŸ¤¯ My brain is officially in \"Transformer overload\" (in the best way possible!) lately. Diving deep into the world of self-attention, positional encodings, and multi-head attention has been absolutely fascinating. It's like unlocking a whole new level of understanding for how these powerful models process language and beyond. So much to learn, so little time! ğŸ§ âœ¨ #Transformers #DeepLearning #AI #MachineLearning #NLP #Tech\n",
       "\n",
       "**Option 2: More Casual & Relatable**\n",
       "\n",
       "Who knew that a single \"Transformer\" could open up so many new ideas? ğŸ¤¯ I've been spending a lot of time lately learning about these incredible models, and my mind is blown by what they can do. It's a bit complex, but the more I dig,"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce82374",
   "metadata": {},
   "source": [
    "Harika. Ancak baÅŸka bir API denemek istediÄŸinizi dÃ¼ÅŸÃ¼nÃ¼n, Ã¶rneÄŸin OpenAI'nin veya Anthropic'in?\n",
    "\n",
    "OnlarÄ±n dokÃ¼mantasyonlarÄ±nÄ± incelemek ve tÃ¼m kodunuzu onlarÄ±n API'sini kullanacak ÅŸekilde yeniden yazmak zorunda kalÄ±rsÄ±nÄ±z. Tabii ki benzer olacaktÄ±r, ancak aynÄ± olmayacaktÄ±r.\n",
    "\n",
    "Neyse ki LangChain var!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b655091d",
   "metadata": {},
   "source": [
    "## LangChain Kullanma ğŸ¦œğŸ”—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151d937e",
   "metadata": {},
   "source": [
    "Neden LangChain kullanÄ±rsÄ±nÄ±z?\n",
    "\n",
    "1. **Model-BaÄŸÄ±msÄ±z Kod**\n",
    "\n",
    "   LangChain, farklÄ± LLM saÄŸlayÄ±cÄ±larÄ± (Google, OpenAI, Anthropic, vb.) arasÄ±nda minimal kod deÄŸiÅŸikliÄŸi ile geÃ§iÅŸ yapmanÄ±zÄ± saÄŸlayan soyutlamalar sunar. Google API'sine doÄŸrudan kod yazarsanÄ±z, saÄŸlayÄ±cÄ± deÄŸiÅŸtirmek Ã¶nemli Ã¶lÃ§Ã¼de yeniden dÃ¼zenleme gerektirir.\n",
    "\n",
    "2. **BirleÅŸik ArayÃ¼z**\n",
    "\n",
    "   LangChain, altta yatan API'den baÄŸÄ±msÄ±z olarak farklÄ± LLM saÄŸlayÄ±cÄ±larÄ± arasÄ±nda etkileÅŸimleri standartlaÅŸtÄ±rÄ±r ve tutarlÄ± yÃ¶ntemler ile yanÄ±t formatlarÄ± sunar.\n",
    "\n",
    "3. **BileÅŸenlerle Ã‡alÄ±ÅŸabilirlik**\n",
    "\n",
    "   LangChain'in zincir ve pipeline mimarisi, tÃ¼m alt yapÄ±yÄ± kendiniz halletmeden prompt, bellek ve eriÅŸim sistemlerini birleÅŸtiren karmaÅŸÄ±k iÅŸ akÄ±ÅŸlarÄ± oluÅŸturmayÄ± kolaylaÅŸtÄ±rÄ±r.\n",
    "\n",
    "4. **YerleÅŸik AraÃ§lar**\n",
    "\n",
    "   LangChain, Ã§Ä±ktÄ± ayrÄ±ÅŸtÄ±rma, prompt ÅŸablonlarÄ± ve kendiniz uygulamanÄ±z gereken diÄŸer yardÄ±mcÄ± araÃ§larÄ± iÃ§erir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3de40d",
   "metadata": {},
   "source": [
    "[LangChain'in chat entegrasyonlarÄ± listesi](https://docs.langchain.com/oss/python/integrations/chat)'ne gidin ve entegrasyon listesine bakÄ±n. Favori LLM saÄŸlayÄ±cÄ±nÄ±zÄ± bulabiliyor musunuz?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a696d71e",
   "metadata": {},
   "source": [
    "Kodumuzda `chat_models.ChatGoogleGenerativeAI` kullanmak istemiyoruz Ã§Ã¼nkÃ¼ bu Ã¶zellikle Gemini iÃ§in yapÄ±lmÄ±ÅŸ. LLM'yi deÄŸiÅŸtirmek istersek, modeli baÅŸlatma ÅŸeklimizi deÄŸiÅŸtirmek zorunda kalÄ±rÄ±z. Neyse ki LangChain bir modeli baÅŸlatmak iÃ§in daha genel bir yol sunar.\n",
    "\n",
    "Gemini'yi tekrar kullanalÄ±m, ancak ÅŸimdi LangChain'in genel Chat Models'ini kullanarak.\n",
    "\n",
    "ğŸ‘‰ [LangChain'in \"Models\" dokÃ¼mantasyonu](https://docs.langchain.com/oss/python/langchain/models) sayfasÄ±na gidin ve Gemini kullanarak bir chat modelinin nasÄ±l baÅŸlatÄ±lacaÄŸÄ±nÄ± bulun.\n",
    "\n",
    "Ä°puÃ§larÄ±:\n",
    "1. Hemen \"Basic Usage\" bÃ¶lÃ¼mÃ¼ne gidin.\n",
    "2. Kullanmak istediÄŸiniz modeli seÃ§erek doÄŸru dokÃ¼mantasyonu hemen gÃ¶rebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ccfa886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T14:11:18.762432Z",
     "iopub.status.busy": "2026-02-02T14:11:18.761768Z",
     "iopub.status.idle": "2026-02-02T14:11:18.928008Z",
     "shell.execute_reply": "2026-02-02T14:11:18.927673Z",
     "shell.execute_reply.started": "2026-02-02T14:11:18.762381Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\n",
    "    \"gemini-2.5-flash-lite\",\n",
    "    model_provider=\"google_genai\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda09697",
   "metadata": {},
   "source": [
    "Modelin en temel kullanÄ±mÄ± sadece `.invoke()` metodunu kullanmaktÄ±r:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22a0abf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T14:11:22.305489Z",
     "iopub.status.busy": "2026-02-02T14:11:22.304928Z",
     "iopub.status.idle": "2026-02-02T14:11:23.363241Z",
     "shell.execute_reply": "2026-02-02T14:11:23.362174Z",
     "shell.execute_reply.started": "2026-02-02T14:11:22.305449Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is **Paris**.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c1eb1-9c43-7321-a423-2f5bc1984fb4-0', usage_metadata={'input_tokens': 7, 'output_tokens': 8, 'total_tokens': 15, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(\"What is the capital of France?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af01745",
   "metadata": {},
   "source": [
    "YanÄ±ta bir gÃ¶z atalÄ±m. Nesnenin tÃ¼m Ã¶znitelik ve metodlarÄ±nÄ± iÃ§eren `__dict__`'ini gÃ¼zel ÅŸekilde yazdÄ±rmak iÃ§in `pprint()` kullanÄ±yoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ccaccd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T14:11:25.309530Z",
     "iopub.status.busy": "2026-02-02T14:11:25.308594Z",
     "iopub.status.idle": "2026-02-02T14:11:25.315487Z",
     "shell.execute_reply": "2026-02-02T14:11:25.314236Z",
     "shell.execute_reply.started": "2026-02-02T14:11:25.309482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_kwargs': {},\n",
      " 'content': 'The capital of France is **Paris**.',\n",
      " 'id': 'lc_run--019c1eb1-9c43-7321-a423-2f5bc1984fb4-0',\n",
      " 'invalid_tool_calls': [],\n",
      " 'name': None,\n",
      " 'response_metadata': {'finish_reason': 'STOP',\n",
      "                       'model_name': 'gemini-2.5-flash-lite',\n",
      "                       'model_provider': 'google_genai',\n",
      "                       'safety_ratings': []},\n",
      " 'tool_calls': [],\n",
      " 'type': 'ai',\n",
      " 'usage_metadata': {'input_token_details': {'cache_read': 0},\n",
      "                    'input_tokens': 7,\n",
      "                    'output_tokens': 8,\n",
      "                    'total_tokens': 15}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(response.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12757572",
   "metadata": {},
   "source": [
    "CevabÄ± Ã§Ä±karÄ±n ve gÃ¶rÃ¼ntÃ¼leyin. Markdown formatÄ±nda olduÄŸunu unutmayÄ±n, bu yÃ¼zden gÃ¼zel gÃ¶rÃ¼nmesini saÄŸlayabilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07169165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T14:11:28.348713Z",
     "iopub.status.busy": "2026-02-02T14:11:28.348246Z",
     "iopub.status.idle": "2026-02-02T14:11:28.354979Z",
     "shell.execute_reply": "2026-02-02T14:11:28.354286Z",
     "shell.execute_reply.started": "2026-02-02T14:11:28.348673Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The capital of France is **Paris**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aff1f6",
   "metadata": {},
   "source": [
    "Modelin temperature deÄŸerini `.temperature` Ã¶zniteliÄŸine eriÅŸerek kontrol edebilirsiniz. Deneyin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e47f8685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T14:11:30.701523Z",
     "iopub.status.busy": "2026-02-02T14:11:30.701060Z",
     "iopub.status.idle": "2026-02-02T14:11:30.708043Z",
     "shell.execute_reply": "2026-02-02T14:11:30.706977Z",
     "shell.execute_reply.started": "2026-02-02T14:11:30.701485Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(model, \"temperature\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c091191",
   "metadata": {},
   "source": [
    "Modeli kullanmadan Ã¶nce, Ã¶zniteliklere yeni deÄŸerler atayarak oluÅŸturma parametrelerini de ayarlayabiliriz.\n",
    "\n",
    "Daha Ã¶nce Google'Ä±n kÃ¼tÃ¼phanesini kullanarak sosyal medya gÃ¶nderisi yazmak iÃ§in yaptÄ±ÄŸÄ±mÄ±zÄ±n eÅŸdeÄŸerini kodlamaya Ã§alÄ±ÅŸÄ±n.\n",
    "\n",
    "> _Not_: Normal olarak modelin `max_output_tokens` deÄŸerini ayarlayabilmemiz gerekir (modeli baÅŸlatÄ±rken veya daha sonra Ã¶zniteliÄŸi deÄŸiÅŸtirerek). _langchain_google_genai_'nin mevcut sÃ¼rÃ¼mÃ¼ (4.1.1) bir [hataya](https://github.com/langchain-ai/langchain-google/issues/1454) sahip ve bu Ã§alÄ±ÅŸmÄ±yor. GeÃ§ici Ã§Ã¶zÃ¼m? `max_output_tokens`'Ä± `.invoke()` metodunun bir parametresi olarak ayarlayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74c6e95b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T14:15:49.291021Z",
     "iopub.status.busy": "2026-02-02T14:15:49.290312Z",
     "iopub.status.idle": "2026-02-02T14:15:50.883756Z",
     "shell.execute_reply": "2026-02-02T14:15:50.882835Z",
     "shell.execute_reply.started": "2026-02-02T14:15:49.290963Z"
    },
    "tags": [
     "steps"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are a few options for a social media post about learning about transformers, ranging in tone and focus. Choose the one that best fits your style!\n",
       "\n",
       "**Option 1: Enthusiastic & Slightly Overwhelmed**\n",
       "\n",
       "> Officially diving deep into the world of Transformers! ğŸ¤¯ My brain is buzzing with concepts like attention mechanisms, self-attention, and the sheer power of these models. It's like unlocking a new level of understanding in AI. So much to learn, so little time, but absolutely loving every minute! #AI #MachineLearning #Transformers #DeepLearning #NLP #LearningJourney\n",
       "\n",
       "**Option 2: Focused on the \"Aha!\" Moments**\n",
       "\n",
       "> Had a major \"aha!\" moment today while learning about Transformers! The way they process sequences by considering relationships between all elements is truly revolutionary. Feeling like I'm starting to grasp the \"why\" behind their incredible performance. So excited to keep building on this! âœ¨ #ArtificialIntelligence #TransformerModels #"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the maximum number of output tokens to 200\n",
    "max_output_tokens = 200\n",
    "\n",
    "# Set the temperature to 1.0\n",
    "model.temperature = 1.0\n",
    "\n",
    "# Generate a response with the new settings\n",
    "response = model.invoke(\n",
    "    \"Write a social media post about how much you're learning about transformers.\",\n",
    "    max_output_tokens=max_output_tokens,\n",
    ")\n",
    "\n",
    "# Display the response\n",
    "from IPython.display import Markdown\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7161e0",
   "metadata": {},
   "source": [
    "Bunun avantajÄ±? Bu LangChain Chat Model birÃ§ok baÅŸka API'yi destekleyebilir.\n",
    "\n",
    "BaÅŸka bir modele geÃ§mek iÃ§in deÄŸiÅŸtirmeniz gereken tek ÅŸeyler:\n",
    "1. DiÄŸer model iÃ§in bir API anahtarÄ± alÄ±n ve kodunuzda tanÄ±mlayÄ±n.\n",
    "2. Modeli baÅŸlatÄ±rken model ve saÄŸlayÄ±cÄ±yÄ± deÄŸiÅŸtirin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ece2f",
   "metadata": {},
   "source": [
    "### Ã‡oklu Mesajlar\n",
    "\n",
    "`.invoke()` fonksiyonunu sadece tek bir mesajla kullanmak biraz kÄ±sÄ±tlayÄ±cÄ±.\n",
    "\n",
    "Åu gibi birden fazla mesaj saÄŸlayabilirsiniz:\n",
    "- `SystemMessage` veya sistem mesajlarÄ±: modelin nasÄ±l davranacaÄŸÄ±nÄ± sÃ¶ylemek iÃ§in\n",
    "- `HumanMessage` veya KullanÄ±cÄ± mesajlarÄ±: kullanÄ±cÄ±dan gelen girdi\n",
    "- `AIMessage` veya Asistan mesajlarÄ±: modelden gelen yanÄ±t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9608581",
   "metadata": {},
   "source": [
    "Bir sosyal medya yazarÄ± yapalÄ±m.\n",
    "\n",
    "Modele nasÄ±l davranacaÄŸÄ±nÄ± aÃ§Ä±klayan bir sistem mesajÄ± gÃ¶ndereceÄŸiz. Sonra kullanÄ±cÄ± mesajÄ±nda, kendimizi sadece yazacaÄŸÄ± konuyu vermekle sÄ±nÄ±rlayabiliriz.\n",
    "\n",
    "Bunu nasÄ±l yapacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸrenmek iÃ§in [LangChain'in \"Messages\" dokÃ¼mantasyonu](https://docs.langchain.com/oss/python/langchain/messages)'na bakÄ±n.\n",
    "\n",
    "Sistem mesajÄ± iÃ§in ilhama mÄ± ihtiyacÄ±nÄ±z var? Ä°ÅŸte baÅŸlamanÄ±z iÃ§in temel bir talimat:\n",
    "\n",
    "```python\n",
    "\"\"\"Sen Ãœretken AI Ã¶ÄŸrencisi iÃ§in gÃ¶nderiler yazan yaratÄ±cÄ± bir sosyal medya yazarÄ±sÄ±n.\n",
    "GÃ¶nderilerinde her zaman kelime oyunu ve harekete geÃ§irici Ã§aÄŸrÄ± bulunur.\n",
    "GÃ¶nderilerin maksimum 200 karakter uzunluÄŸundadÄ±r.\n",
    "Her zaman emoji kullanÄ±rsÄ±n.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "383b2645",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T14:16:50.347843Z",
     "iopub.status.busy": "2026-02-02T14:16:50.347334Z",
     "iopub.status.idle": "2026-02-02T14:16:51.402934Z",
     "shell.execute_reply": "2026-02-02T14:16:51.401647Z",
     "shell.execute_reply.started": "2026-02-02T14:16:50.347805Z"
    },
    "tags": [
     "steps"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Transformerlar hakkÄ±nda bilgi ediniyorum, beynim adeta bir \"dÃ¶nÃ¼ÅŸÃ¼m\" yaÅŸÄ±yor! ğŸ¤– Ã–ÄŸrenmeye devam edin, siz de \"transformer\" olun! ğŸ˜‰ #yapayzeka #derinnogrenme #transformer"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary classes\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Create a list of messages\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=(\n",
    "            \"Sen Ãœretken AI Ã¶ÄŸrencisi iÃ§in gÃ¶nderiler yazan yaratÄ±cÄ± bir sosyal medya yazarÄ±sÄ±n.\\n\"\n",
    "            \"GÃ¶nderilerinde her zaman kelime oyunu ve harekete geÃ§irici Ã§aÄŸrÄ± bulunur.\\n\"\n",
    "            \"GÃ¶nderilerin maksimum 200 karakter uzunluÄŸundadÄ±r.\\n\"\n",
    "            \"Her zaman emoji kullanÄ±rsÄ±n.\"\n",
    "        )\n",
    "    ),\n",
    "    HumanMessage(content=\"BugÃ¼n transformerlarÄ± Ã¶ÄŸreniyorum. KÄ±sa, eÄŸlenceli bir post yaz.\"),\n",
    "]\n",
    "\n",
    "# Generate a response using the list of messages\n",
    "response = model.invoke(messages, max_output_tokens=200)\n",
    "\n",
    "# Display the response\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782559c7",
   "metadata": {},
   "source": [
    "ğŸ Tebrikler! ArtÄ±k LangChain kullanarak Ã§oklu mesajlarla temel prompt yazma konusunda uzmanlaÅŸtÄ±nÄ±z."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
